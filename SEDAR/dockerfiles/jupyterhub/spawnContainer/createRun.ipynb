{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Run in an Experiment in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the MLFlow-Tracking Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://mlflow_server:6798\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Experiment to which the Run is to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = \"XXXXXXXXXXXX\"\n",
    "\n",
    "mlflow.set_experiment(experiment_id=exp_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the Metrics on which the Run should be evaluated\n",
    "Possible Metrics: \\n\n",
    "\n",
    "| Description      | Class |\n",
    "| ----------- | ----------- |\n",
    "| Explained variance regression score function      | explained_variance_score       |\n",
    "| The max_error metric calculates the maximum residual error   | max_error        |\n",
    "|Mean absolute error regression loss|mean_absolute_error|\n",
    "|Mean squared error regression loss|mean_squared_error|\n",
    "|Mean squared logarithmic error regression loss|mean_squared_log_error|\n",
    "|Median absolute error regression loss|median_absolute_error|\n",
    "|Mean absolute percentage error (MAPE) regression loss|mean_absolute_percentage_error|\n",
    "|R2(coefficient of determination) regression score function|r2_score|\n",
    "|Mean Poisson deviance regression loss|mean_poisson_deviance|\n",
    "|Mean Gamma deviance regression loss|mean_gamma_deviance|\n",
    "|Mean Tweedie deviance regression loss|mean_tweedie_deviance|\n",
    "|D2 regression score function, fraction of Tweedie deviance explained|d2_tweedie_score|\n",
    "|Pinball loss for quantile regression|mean_pinball_loss|\n",
    "|D2 regression score function, fraction of pinball loss explained|d2_pinball_score|\n",
    "|D2 regression score function, fraction of absolute error explained|d2_absolute_error_score|\n",
    "|Accuracy classification score|accuracy_score|\n",
    "|Compute Area Under the Curve (AUC) using the trapezoidal rule|auc|\n",
    "|Compute average precision (AP) from prediction scores|average_precision_score|\n",
    "|Compute the balanced accuracy|balanced_accuracy_score|\n",
    "|Compute the Brier score loss|brier_score_loss|\n",
    "|Build a text report showing the main classification metrics|classification_report|\n",
    "|Compute Cohen's kappa: a statistic that measures inter-annotator agreement|cohen_kappa_score|\n",
    "|Compute confusion matrix to evaluate the accuracy of a classification|confusion_matrix|\n",
    "|Compute the F1 score, also known as balanced F-score or F-measure|f1_score|\n",
    "|Compute the F-beta score|fbeta_score|\n",
    "|Compute the average Hamming loss|hamming_loss|\n",
    "|Jaccard similarity coefficient score|jaccard_score|\n",
    "|Log loss, aka logistic loss or cross-entropy loss|log_loss|\n",
    "|Compute the Matthews correlation coefficient (MCC)|matthews_corrcoef|\n",
    "|Compute a confusion matrix for each class or sample|multilabel_confusion_matrix|\n",
    "|Compute precision-recall pairs for different probability thresholds|precision_recall_curve|\n",
    "|Compute precision, recall, F-measure and support for each class|precision_recall_fscore_support|\n",
    "|Compute the precision|precision_score|\n",
    "|Compute the recall|recall_score|\n",
    "|Zero-one classification loss|zero_one_loss|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example with mean_squared_error, mean_absolute_error, r2_score\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_dataSet_json(data_path, column):\n",
    "    data = pd.read_json(data_path)\n",
    "    train, test = train_test_split(data)\n",
    "    train_x = train.drop([column], axis=1)\n",
    "    test_x = test.drop([column], axis=1)\n",
    "    train_y = train[[column]]\n",
    "    test_y = test[[column]]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainings-Function\n",
    "Possible Model-Classes:\n",
    "| Classes | Parameters |\n",
    "| ----------- | ----------- |\n",
    "| linear_model.LinearRegression      |*, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False|\n",
    "| linear_model.Ridge      | alpha=1.0, *, fit_intercept=True, normalize='deprecated', copy_X=True, max_iter=None, tol=0.001, solver='auto', positive=False, random_state=None|\n",
    "|linear_model.Lasso| alpha=1.0, *, fit_intercept=True, normalize='deprecated', precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic'|\n",
    "|linear_model.MultiTaskLasso| alpha=1.0, *, fit_intercept=True, normalize='deprecated', copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, random_state=None, selection='cyclic'|\n",
    "|linear_model.ElasticNet| alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize='deprecated', precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic'|\n",
    "|linear_model.MultiTaskElasticNet| alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize='deprecated', copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, random_state=None, selection='cyclic'|\n",
    "|linear_model.Lars| *, fit_intercept=True, verbose=False, normalize='deprecated', precompute='auto', n_nonzero_coefs=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, jitter=None, random_state=None|\n",
    "|linear_model.LassoLars|alpha=1.0, *, fit_intercept=True, verbose=False, normalize='deprecated', precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, positive=False, jitter=None, random_state=None |\n",
    "|linear_model.OrthogonalMatchingPursuit|*, n_nonzero_coefs=None, tol=None, fit_intercept=True, normalize='deprecated', precompute='auto' |\n",
    "|linear_model.BayesianRidge|*, n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, alpha_init=None, lambda_init=None, compute_score=False, fit_intercept=True, normalize='deprecated', copy_X=True, verbose=False |\n",
    "|linear_model.LogisticRegression|penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None |\n",
    "|linear_model.TweedieRegressor|*, power=0.0, alpha=1.0, fit_intercept=True, link='auto', max_iter=100, tol=0.0001, warm_start=False, verbose=0 |\n",
    "|linear_model.SGDRegressor|loss='squared_error', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01, power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False |\n",
    "|linear_model.Perceptron| *, penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False|\n",
    "|linear_model.PassiveAggressiveClassifier|*, C=1.0, fit_intercept=True, max_iter=1000, tol=0.001, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, shuffle=True, verbose=0, loss='hinge', n_jobs=None, random_state=None, warm_start=False, class_weight=None, average=False |\n",
    "|linear_model.HuberRegressor|*, epsilon=1.35, max_iter=100, alpha=0.0001, warm_start=False, fit_intercept=True, tol=1e-05|\n",
    "|linear_model.QuantileRegressor| *, quantile=0.5, alpha=1.0, fit_intercept=True, solver='interior-point', solver_options=None|\n",
    "|linear_model.LinearRegression| *, fit_intercept=True, normalize='deprecated', copy_X=True, n_jobs=None, positive=False|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(parameters):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "    datasets = []\n",
    "    #Define the train Column\n",
    "    train_x, train_y, test_x, test_y = load_data_dataSet_json(datasets[0], \"XXXXXXXXX\")\n",
    "    with mlflow.start_run():\n",
    "        # Execute Model\n",
    "        # Example here with ElasticNet\n",
    "        # look at other Possibilities above\n",
    "        lr = linear_model.ElasticNet(alpha=parameters[0], l1_ratio=parameters[1], random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "        #Change to above defined Metrics \n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        # Change to the Parameters defined in the section above\n",
    "        \n",
    "        mlflow.log_param(key=\"XXXX\", value=parameters[0])\n",
    "        mlflow.log_param(key=\"l1_ratio\", value=parameters[1])\n",
    "        mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "        mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "        \n",
    "        data_path = \"/home/jovyan/work/tmp/dataset.txt\" \n",
    "        with open(data_path, 'w') as f:\n",
    "            f.write(datasets[0])\n",
    "        mlflow.log_artifact(data_path)\n",
    "        os.remove(data_path)\n",
    "\n",
    "        \n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train([0.5, 0.5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
